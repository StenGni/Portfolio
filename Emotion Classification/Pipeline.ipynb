{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import assemblyai as aai\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import torch\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: API Key Setup & File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AssemblyAI API key\n",
    "API_KEY = \"xxx\"\n",
    "aai.settings.api_key = API_KEY\n",
    "\n",
    "# Polish audio MP3 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\legak\\Documents\\GitHub\\Y2 repos\\2024-25c-fai2-adsai-group-group22_y2c\\task 2\\Sondy uliczne, wywiady z lud≈∫mi. Jak jest pod koniec wakacji w Ustce  Studio Promenada 25.08.2022.mp3\",\n",
    "    r\"C:\\Users\\legak\\Documents\\GitHub\\Y2 repos\\2024-25c-fai2-adsai-group-group22_y2c\\task 2\\TE TEKSTY PRZEJDƒÑ DO HISTORII! Najlepsze sondy uliczne z emerytami.mp3\"\n",
    "]\n",
    "file_paths = [os.path.normpath(p) for p in file_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Upload Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(filepath):\n",
    "    headers = {'authorization': API_KEY}\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        response = requests.post(\"https://api.assemblyai.com/v2/upload\", headers=headers, files={\"file\": f})\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Uploaded: {filepath}\")\n",
    "        return response.json()[\"upload_url\"]\n",
    "    else:\n",
    "        raise Exception(f\"‚ùå Upload failed: {response.text}\")\n",
    "\n",
    "def request_transcription(upload_url):\n",
    "    print(\"üìù Requesting transcription...\")\n",
    "    config = aai.TranscriptionConfig(language_code=\"pl\", punctuate=True)\n",
    "    transcriber = aai.Transcriber()\n",
    "    transcript = transcriber.transcribe(upload_url, config=config)\n",
    "    if transcript.status == aai.TranscriptStatus.error:\n",
    "        raise Exception(f\"‚ùå Transcription failed: {transcript.error}\")\n",
    "    return transcript.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Transcription Request Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transcription_to_csv(text, output_file):\n",
    "    sentences = re.split(r'(?<=[.!?])\\\\s+', text)\n",
    "    df = pd.DataFrame({\"pl_text\": sentences})\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"üíæ Saved transcription: {output_file}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Save to CSV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_and_return_dfs():\n",
    "    all_dfs = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            print(f\"\\nüöÄ Processing: {path}\")\n",
    "            upload_url = upload_file(path)\n",
    "            transcription = request_transcription(upload_url)\n",
    "            csv_path = path.replace(\".mp3\", \"_assembly_pl.csv\")\n",
    "            df = save_transcription_to_csv(transcription, csv_path)\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with {path}: {e}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"‚ùå No valid audio transcribed. Please check your files.\")\n",
    "        return pd.DataFrame(columns=[\"pl_text\"])\n",
    "    \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Main Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pl_en_model_name = \"Helsinki-NLP/opus-mt-pl-en\"\n",
    "pl_en_tokenizer = AutoTokenizer.from_pretrained(pl_en_model_name)\n",
    "pl_en_model = AutoModelForSeq2SeqLM.from_pretrained(pl_en_model_name)\n",
    "\n",
    "# Automatically uses GPU if available\n",
    "translator = pipeline(\n",
    "    \"translation\", \n",
    "    model=pl_en_model, \n",
    "    tokenizer=pl_en_tokenizer, \n",
    "    framework=\"pt\", \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def translate_texts(texts):\n",
    "    return [translator(text)[0]['translation_text'] for text in tqdm(texts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "checkpoint_path = \"./checkpoint-3906\"\n",
    "label_encoder_path = \"label_encoder.pkl\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load LabelEncoder ---\n",
    "with open(label_encoder_path, \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# --- Load Model and Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- Emotion Classification Function ---\n",
    "def classify_emotions_transformer(texts):\n",
    "    emotions = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            label = label_encoder.inverse_transform([pred])[0]\n",
    "        emotions.append(label)\n",
    "    return emotions\n",
    "\n",
    "# --- Apply Classification ---\n",
    "pl_df[\"emotion\"] = classify_emotions_transformer(pl_df[\"en_translation\"].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Output DataFrame ---\n",
    "final_df = pl_df[[\"pl_text\", \"en_translation\", \"emotion\"]].copy()\n",
    "final_df.columns = [\"Sentence\", \"Translation\", \"Emotion\"]\n",
    "\n",
    "# --- Save Result ---\n",
    "final_df.to_csv(\"final_output.csv\", index=False)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pipelinev3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
